- hosts: "{{ env }}_app"
  # beer ransom for whoever figures out how to make these vars_files optional so
  # that we don't need empty vault files for projects with no secrets
  vars_files:
    - "{{ config_dir }}/config.common.yml"
    - "{{ config_dir }}/config.{{ env }}.yml"
    - "{{ vault_dir }}/{{ project_name }}/vault.{{ env }}.yml"
  gather_facts: false
  become: yes
  become_user: "{{ application_user }}"
  become_method: sudo
  

  # For whatever reason, for new deployments, it seems like nginx is not
  # getting restarted at the right time. Thus for new deploys only, it is
  # necessary to manually kick nginx.
  #
  # ^ this may no longer be true. Some changes were made b/c nginx was not
  # restarting in general and might have fixed this for new deploys.
  # See further notes in deploy.web.yml

  tasks:

    - name: Template .env environment file
      template:
        src: templates/env.j2
        dest: "{{ env_file }}"
      notify:
        - restart appserver

    - name: Template envrc startup script
      template:
        src: templates/envrc.j2
        dest: "{{ envrc_file }}"
      notify:
        - restart appserver
        - allow envrc

    - name: Template systemd config
      template:
        src: templates/systemd.j2
        dest: "/etc/systemd/system/{{ service_name }}.service"
        owner: root
        group: root
        mode: 0644
      become: yes
      become_user: root
      become_method: sudo
      notify:
        - restart appserver
        - restart nginx

    - name: install python packages
      pip:
        requirements={{ requirements_file }}
        virtualenv={{ virtualenv }}
        virtualenv_python={{ python }}
      notify:
        - restart appserver
        - restart nginx

    - name: set project location in virtual environment
      template:
        src=templates/project.j2
        dest="{{ virtualenv }}/.project"

    - name: django migrate
      when: type == "django" and (django_migrate is undefined or django_migrate)
      # django manage.py command does not support env vars, thus shell instead
      shell: "{{ env_run_script }} ./manage.py migrate --noinput"
      args:
        chdir: "{{ application_dir }}"

    # service module is really flaky on custom upstart scripts. It seems more
    # consistent to use raw calls to service. This also requires sudoers:
    # apps    ALL=(ALL) NOPASSWD:ALL
    # Per various discussions, it seems like this is just how it is. See, e.g.:
    # https://github.com/ansible/ansible/issues/5712

    # Be sure service permissions are accessible by ansible user
    - name: make sure application server is running
      #  should we be using shell or command here instead of raw?
      raw: if (sudo systemctl status {{ service_name }} |grep Stop); then sudo systemctl start {{ service_name }} ; fi


  handlers:
    - name: restart appserver
      raw: sudo systemctl restart {{ service_name }}
    - name: restart nginx
      shell: sudo systemctl restart nginx
        warn=False
    - name: allow envrc
      shell: direnv allow .
      args:
        chdir: "{{ application_dir }}"
